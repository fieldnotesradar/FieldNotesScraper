name: Scrape
on:
  workflow_dispatch:
    inputs:
      lookback:
        description: 'Lookback period (minutes)'
      tweet:
        description: 'Allow Tweet if changes are detected'
        default: false
        type: boolean
  schedule:
  - cron: '* * * * *' # continuous
  - cron: '12 3 * * *' # daily
env:
  DEFAULT_LOOKBACK: '60'
  LOOKBACK: ${{ github.event.inputs.lookback }}
  TWEET: ${{ github.event.inputs.tweet || true }}
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v2
      - name: Python setup
        run: pip install scrapy arrow
      - name: Set unlimited lookback period
        run: echo "LOOKBACK=" >> $GITHUB_ENV
        if: github.event.schedule == '12 3 * * *'
      # TODO: set range to last time workflow ran
      - name: Set default lookback period
        run: echo "LOOKBACK=$DEFAULT_LOOKBACK" >> $GITHUB_ENV
        if: github.event.schedule == '* * * * *'
      - name: Run scrape spider
        run: scrapy runspider scrape.py -O updates.json -a minutes=$LOOKBACK
      - name: Merge JSON
        run: python merge.py
      - name: Commit changes
        uses: EndBug/add-and-commit@v8
        id: commit
        with:
          message: 'Update tracked Field Notes website data'
          add: 'results.json'
      - name: Tweet changes
        uses: ethomson/send-tweet-action@v1
        if: ${{ steps.commit.outputs.committed != 'undefined' && env.TWEET == 'true' }}
        with:
          status: "An update has been detected on the Field Notes website! https://github.com/fieldnotesradar/FieldNotesScraper/commit/${{ steps.commit.outputs.commit_long_sha }}"
          consumer-key: ${{ secrets.TWITTER_CONSUMER_API_KEY }}
          consumer-secret: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}
          access-token: ${{ secrets.TWITTER_ACCESS_TOKEN }}
          access-token-secret: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}